{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EJERCICIO"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### *IMPORTO BIBLIOTECAS*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-04-15 07:39:59.732182: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-04-15 07:39:59.794179: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-04-15 07:40:00.077403: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-04-15 07:40:00.188373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1744702800.414828    5868 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1744702800.503480    5868 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1744702800.777022    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744702800.777055    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744702800.777057    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744702800.777059    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-04-15 07:40:00.801073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Corrección aquí\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, SeparableConv2D, Flatten, Dense, Input, Dropout, BatchNormalization, Lambda, GlobalAveragePooling2D\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "from tensorflow.keras.optimizers import Adam \n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import numpy as np\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### *CARGO LOS DATOS*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 0 images belonging to 0 classes.\n"
                    ]
                },
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '/workspaces/TensorFlow-Pet-Classifier/data/train'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     11\u001b[39m train_generator = train_datagen.flow_from_directory(\n\u001b[32m     12\u001b[39m     directory=\u001b[33m\"\u001b[39m\u001b[33m/workspaces/23-PILAR-DEEPLEARNINGG/data/train\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     target_size=(\u001b[32m200\u001b[39m, \u001b[32m200\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     subset=\u001b[33m\"\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Indicar que son imágenes de entrenamiento\u001b[39;00m\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Cargar imágenes de validación (20% de train/)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m validation_generator = \u001b[43mtrain_datagen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/workspaces/TensorFlow-Pet-Classifier/data/train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Indicar que son imágenes de validación\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1138\u001b[39m, in \u001b[36mImageDataGenerator.flow_from_directory\u001b[39m\u001b[34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow_from_directory\u001b[39m(\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1122\u001b[39m     directory,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1136\u001b[39m     keep_aspect_ratio=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1137\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:453\u001b[39m, in \u001b[36mDirectoryIterator.__init__\u001b[39m\u001b[34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m    452\u001b[39m     classes = []\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os.listdir(directory)):\n\u001b[32m    454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(os.path.join(directory, subdir)):\n\u001b[32m    455\u001b[39m             classes.append(subdir)\n",
                        "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/TensorFlow-Pet-Classifier/data/train'"
                    ]
                }
            ],
            "source": [
                "# Generador de imágenes con separación de validación\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    validation_split=0.2,  # 20% de las imágenes de entrenamiento se usarán para validación\n",
                "    shear_range=0.2,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True\n",
                ")\n",
                "\n",
                "# Cargar imágenes de entrenamiento (80% de train/)\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    directory=\"/workspaces/23-PILAR-DEEPLEARNINGG/data/train\",\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='binary',\n",
                "    subset=\"training\"  # Indicar que son imágenes de entrenamiento\n",
                ")\n",
                "\n",
                "# Cargar imágenes de validación (20% de train/)\n",
                "validation_generator = train_datagen.flow_from_directory(\n",
                "    directory=\"/workspaces/TensorFlow-Pet-Classifier/data/train\",\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='binary',\n",
                "    subset=\"validation\"  # Indicar que son imágenes de validación\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
                        "2025-04-15 07:49:59.446086: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
                    ]
                }
            ],
            "source": [
                "# Definir el modelo\n",
                "model = Sequential([\n",
                "    Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
                "    MaxPool2D(2, 2),\n",
                "    \n",
                "    Conv2D(64, (3, 3), activation='relu'),\n",
                "    MaxPool2D(2, 2),\n",
                "    \n",
                "    Conv2D(128, (3, 3), activation='relu'),\n",
                "    MaxPool2D(2, 2),\n",
                "    \n",
                "    Flatten(),\n",
                "    Dense(128, activation='relu'),\n",
                "    Dropout(0.5),\n",
                "    Dense(1, activation='sigmoid')  # Clasificación binaria (perro o gato)\n",
                "])\n",
                "\n",
                "# Compilar el modelo\n",
                "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'ModelCheckpoint' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Callbacks para mejorar el entrenamiento\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m checkpoint = \u001b[43mModelCheckpoint\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33m/workspaces/TensorFlow-Pet-Classifier/models/best_model.h5\u001b[39m\u001b[33m\"\u001b[39m, monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, verbose=\u001b[32m1\u001b[39m, save_best_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m early_stop = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m5\u001b[39m, verbose=\u001b[32m1\u001b[39m, mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m reduce_lr = ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.2\u001b[39m, patience=\u001b[32m3\u001b[39m, min_lr=\u001b[32m0.0001\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'ModelCheckpoint' is not defined"
                    ]
                }
            ],
            "source": [
                "# Callbacks para mejorar el entrenamiento\n",
                "checkpoint = ModelCheckpoint(\"/workspaces/TensorFlow-Pet-Classifier/models/best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
                "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='max')\n",
                "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'validation_generator' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[32m      2\u001b[39m history = model.fit(\n\u001b[32m      3\u001b[39m     train_generator,\n\u001b[32m      4\u001b[39m     steps_per_epoch=\u001b[38;5;28mlen\u001b[39m(train_generator),\n\u001b[32m      5\u001b[39m     epochs=\u001b[32m10\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     validation_data=\u001b[43mvalidation_generator\u001b[49m,\n\u001b[32m      7\u001b[39m     validation_steps=\u001b[38;5;28mlen\u001b[39m(validation_generator),\n\u001b[32m      8\u001b[39m     callbacks=[checkpoint, early_stop, reduce_lr]\n\u001b[32m      9\u001b[39m )\n",
                        "\u001b[31mNameError\u001b[39m: name 'validation_generator' is not defined"
                    ]
                }
            ],
            "source": [
                "# Entrenar el modelo\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    steps_per_epoch=len(train_generator),\n",
                "    epochs=10,\n",
                "    validation_data=validation_generator,\n",
                "    validation_steps=len(validation_generator),\n",
                "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'history' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Extraer métricas del entrenamiento\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history_dict = \u001b[43mhistory\u001b[49m.history\n\u001b[32m      3\u001b[39m epochs_range = \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(history_dict[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Crear la figura\u001b[39;00m\n",
                        "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
                    ]
                }
            ],
            "source": [
                "\n",
                "# Extraer métricas del entrenamiento\n",
                "history_dict = history.history\n",
                "epochs_range = range(len(history_dict['loss']))\n",
                "\n",
                "# Crear la figura\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# Gráfica de la pérdida (Loss)\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(epochs_range, history_dict['loss'], label='Pérdida en entrenamiento')\n",
                "plt.plot(epochs_range, history_dict['val_loss'], label='Pérdida en validación')\n",
                "plt.xlabel('Épocas')\n",
                "plt.ylabel('Pérdida')\n",
                "plt.legend()\n",
                "plt.title('Evolución de la Pérdida')\n",
                "\n",
                "# Gráfica de la precisión (Accuracy)\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(epochs_range, history_dict['accuracy'], label='Precisión en entrenamiento')\n",
                "plt.plot(epochs_range, history_dict['val_accuracy'], label='Precisión en validación')\n",
                "plt.xlabel('Épocas')\n",
                "plt.ylabel('Precisión')\n",
                "plt.legend()\n",
                "plt.title('Evolución de la Precisión')\n",
                "\n",
                "# Mostrar la figura\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '/workspaces/TensorFlow-Pet-Classifier/data/test'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Evaluar 10 imágenes aleatorias de prueba\u001b[39;00m\n\u001b[32m     25\u001b[39m test_directory = \u001b[33m\"\u001b[39m\u001b[33m/workspaces/TensorFlow-Pet-Classifier/data/test\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m test_images = [os.path.join(test_directory, fname) \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_directory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m fname.endswith(\u001b[33m'\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m fname.endswith(\u001b[33m'\u001b[39m\u001b[33m.png\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Seleccionar 10 imágenes aleatorias\u001b[39;00m\n\u001b[32m     29\u001b[39m random_images = np.random.choice(test_images, \u001b[32m10\u001b[39m, replace=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                        "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/workspaces/TensorFlow-Pet-Classifier/data/test'"
                    ]
                }
            ],
            "source": [
                "# Función para predecir y mostrar múltiples imágenes\n",
                "def predict_and_plot_grid(model, img_paths, threshold=0.5):\n",
                "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2 filas, 5 columnas\n",
                "    \n",
                "    for ax, img_path in zip(axes.flatten(), img_paths):\n",
                "        img = image.load_img(img_path, target_size=(200, 200))\n",
                "        img_array = image.img_to_array(img)\n",
                "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
                "\n",
                "        prediction = model.predict(img_array)\n",
                "        pred_label = \"Perro \" if prediction[0][0] > threshold else \"Gato \"\n",
                "        prob = float(prediction[0][0]) if pred_label == \"Perro \" else 1 - float(prediction[0][0])\n",
                "\n",
                "        img_bgr = cv2.imread(img_path)\n",
                "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "        ax.imshow(img_rgb)\n",
                "        ax.set_title(f\"{pred_label}\\n({prob*100:.2f}%)\")\n",
                "        ax.axis(\"off\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Evaluar 10 imágenes aleatorias de prueba\n",
                "test_directory = \"/workspaces/TensorFlow-Pet-Classifier/data/test\"\n",
                "test_images = [os.path.join(test_directory, fname) for fname in os.listdir(test_directory) if fname.endswith('.jpg') or fname.endswith('.png')]\n",
                "\n",
                "# Seleccionar 10 imágenes aleatorias\n",
                "random_images = np.random.choice(test_images, 10, replace=False)\n",
                "predict_and_plot_grid(model, random_images)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
