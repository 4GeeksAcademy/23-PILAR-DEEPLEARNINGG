{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EJERCICIO"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### *IMPORTO BIBLIOTECAS*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-04-15 07:39:59.732182: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
                        "2025-04-15 07:39:59.794179: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-04-15 07:40:00.077403: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
                        "2025-04-15 07:40:00.188373: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1744702800.414828    5868 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1744702800.503480    5868 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1744702800.777022    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744702800.777055    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744702800.777057    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1744702800.777059    5868 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-04-15 07:40:00.801073: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Corrección aquí\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPool2D, SeparableConv2D, Flatten, Dense, Input, Dropout, BatchNormalization, Lambda, GlobalAveragePooling2D\n",
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
                "from tensorflow.keras.optimizers import Adam \n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                "import numpy as np\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### *CARGO LOS DATOS*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "ename": "IndentationError",
                    "evalue": "unexpected indent (1697047779.py, line 12)",
                    "output_type": "error",
                    "traceback": [
                        "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdirectory=\"/workspaces/233-PILAR-/data/train\",\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
                    ]
                }
            ],
            "source": [
                "# Generador de imágenes con separación de validación\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    validation_split=0.2,  # 20% de las imágenes de entrenamiento se usarán para validación\n",
                "    shear_range=0.2,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True\n",
                ")\n",
                "\n",
                "# Cargar imágenes de entrenamiento (80% de train/)\n",
                "\n",
                "    directory=\"/workspaces/233-PILAR-/data/train\",\n",
                "    target_size=(200train_generator = train_datagen.flow_from_directory(, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='binary',\n",
                "    subset=\"training\"  # Indicar que son imágenes de entrenamiento\n",
                ")\n",
                "\n",
                "# Cargar imágenes de validación (20% de train/)\n",
                "validation_generator = train_datagen.flow_from_directory(\n",
                "    directory=\"/workspaces/TensorFlow-Pet-Classifier/data/train\",\n",
                "    target_size=(200, 200),\n",
                "    batch_size=32,\n",
                "    class_mode='binary',\n",
                "    subset=\"validation\"  # Indicar que son imágenes de validación\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'Sequential' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Definir el modelo\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mSequential\u001b[49m([\n\u001b[32m      3\u001b[39m     Conv2D(\u001b[32m32\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, input_shape=(\u001b[32m200\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m3\u001b[39m)),\n\u001b[32m      4\u001b[39m     MaxPool2D(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m     Conv2D(\u001b[32m64\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      7\u001b[39m     MaxPool2D(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     Conv2D(\u001b[32m128\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     MaxPool2D(\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m     Flatten(),\n\u001b[32m     13\u001b[39m     Dense(\u001b[32m128\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     14\u001b[39m     Dropout(\u001b[32m0.5\u001b[39m),\n\u001b[32m     15\u001b[39m     Dense(\u001b[32m1\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Clasificación binaria (perro o gato)\u001b[39;00m\n\u001b[32m     16\u001b[39m ])\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Compilar el modelo\u001b[39;00m\n\u001b[32m     19\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
                        "\u001b[31mNameError\u001b[39m: name 'Sequential' is not defined"
                    ]
                }
            ],
            "source": [
                "# Definir el modelo\n",
                "model = Sequential([\n",
                "    Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)),\n",
                "    MaxPool2D(2, 2),\n",
                "    \n",
                "    Conv2D(64, (3, 3), activation='relu'),\n",
                "    MaxPool2D(2, 2),\n",
                "    \n",
                "    Conv2D(128, (3, 3), activation='relu'),\n",
                "    MaxPool2D(2, 2),\n",
                "    \n",
                "    Flatten(),\n",
                "    Dense(128, activation='relu'),\n",
                "    Dropout(0.5),\n",
                "    Dense(1, activation='sigmoid')  # Clasificación binaria (perro o gato)\n",
                "])\n",
                "\n",
                "# Compilar el modelo\n",
                "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Callbacks para mejorar el entrenamiento\n",
                "checkpoint = ModelCheckpoint(\"/workspaces/TensorFlow-Pet-Classifier/models/best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
                "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1, mode='max')\n",
                "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Entrenar el modelo\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    steps_per_epoch=len(train_generator),\n",
                "    epochs=10,\n",
                "    validation_data=validation_generator,\n",
                "    validation_steps=len(validation_generator),\n",
                "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Extraer métricas del entrenamiento\n",
                "history_dict = history.history\n",
                "epochs_range = range(len(history_dict['loss']))\n",
                "\n",
                "# Crear la figura\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "# Gráfica de la pérdida (Loss)\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(epochs_range, history_dict['loss'], label='Pérdida en entrenamiento')\n",
                "plt.plot(epochs_range, history_dict['val_loss'], label='Pérdida en validación')\n",
                "plt.xlabel('Épocas')\n",
                "plt.ylabel('Pérdida')\n",
                "plt.legend()\n",
                "plt.title('Evolución de la Pérdida')\n",
                "\n",
                "# Gráfica de la precisión (Accuracy)\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(epochs_range, history_dict['accuracy'], label='Precisión en entrenamiento')\n",
                "plt.plot(epochs_range, history_dict['val_accuracy'], label='Precisión en validación')\n",
                "plt.xlabel('Épocas')\n",
                "plt.ylabel('Precisión')\n",
                "plt.legend()\n",
                "plt.title('Evolución de la Precisión')\n",
                "\n",
                "# Mostrar la figura\n",
                "plt.tight_layout()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Función para predecir y mostrar múltiples imágenes\n",
                "def predict_and_plot_grid(model, img_paths, threshold=0.5):\n",
                "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))  # 2 filas, 5 columnas\n",
                "    \n",
                "    for ax, img_path in zip(axes.flatten(), img_paths):\n",
                "        img = image.load_img(img_path, target_size=(200, 200))\n",
                "        img_array = image.img_to_array(img)\n",
                "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
                "\n",
                "        prediction = model.predict(img_array)\n",
                "        pred_label = \"Perro \" if prediction[0][0] > threshold else \"Gato \"\n",
                "        prob = float(prediction[0][0]) if pred_label == \"Perro \" else 1 - float(prediction[0][0])\n",
                "\n",
                "        img_bgr = cv2.imread(img_path)\n",
                "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
                "\n",
                "        ax.imshow(img_rgb)\n",
                "        ax.set_title(f\"{pred_label}\\n({prob*100:.2f}%)\")\n",
                "        ax.axis(\"off\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "# Evaluar 10 imágenes aleatorias de prueba\n",
                "test_directory = \"/workspaces/TensorFlow-Pet-Classifier/data/test\"\n",
                "test_images = [os.path.join(test_directory, fname) for fname in os.listdir(test_directory) if fname.endswith('.jpg') or fname.endswith('.png')]\n",
                "\n",
                "# Seleccionar 10 imágenes aleatorias\n",
                "random_images = np.random.choice(test_images, 10, replace=False)\n",
                "predict_and_plot_grid(model, random_images)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
